{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfd3b082",
   "metadata": {},
   "source": [
    "Decision Tree ID3\n",
    "Write a program to demonstrate the working of the decision tree based ID3 algorithm. Use an appropriate data set for building the decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a61b2f3",
   "metadata": {},
   "source": [
    "Loads the Iris dataset: The dataset contains 150 samples with four features and three classes.\n",
    "Splits the dataset: The data is split into training (70%) and testing (30%) sets.\n",
    "Initializes the classifier: The DecisionTreeClassifier is initialized with criterion='entropy' to use entropy and information gain for splitting.\n",
    "Trains the classifier: The classifier is trained using the training data.\n",
    "Makes predictions: The trained model predicts the labels for the test set.\n",
    "Calculates accuracy: The accuracy of the model is calculated.\n",
    "Prints the classification report: This report includes precision, recall, f1-score, and support for each class.\n",
    "Prints actual vs predicted labels: The first 10 actual and predicted labels are printed for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8563a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.78%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.93      1.00      0.96        13\n",
      "           2       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.97      0.97        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "\n",
      "Actual vs Predicted labels for the first 10 samples:\n",
      "Actual: 1, Predicted: 1\n",
      "Actual: 0, Predicted: 0\n",
      "Actual: 2, Predicted: 2\n",
      "Actual: 1, Predicted: 1\n",
      "Actual: 1, Predicted: 1\n",
      "Actual: 0, Predicted: 0\n",
      "Actual: 1, Predicted: 1\n",
      "Actual: 2, Predicted: 2\n",
      "Actual: 1, Predicted: 1\n",
      "Actual: 1, Predicted: 1\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the Decision Tree Classifier with entropy criterion\n",
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Print the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the first 10 actual vs predicted labels\n",
    "print(\"\\nActual vs Predicted labels for the first 10 samples:\")\n",
    "for actual, predicted in zip(y_test[:10], y_pred[:10]):\n",
    "    print(f\"Actual: {actual}, Predicted: {predicted}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86159639",
   "metadata": {},
   "source": [
    "Decision Tree ID3\n",
    "Write a program to demonstrate the working of the decision tree based ID3 algorithm. Use an appropriate data set for building the decision tree (apply this knowledge to classify a new sample)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c79e39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      "{'outlook': {'overcast': 'yes', 'sunny': {'humidity': {'high': 'no', 'normal': 'yes'}}, 'rainy': {'windy': {False: 'yes', True: 'no'}}}}\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def entropy(data):\n",
    "    \"\"\" Calculate the entropy of a dataset \"\"\"\n",
    "    labels = [item['label'] for item in data]\n",
    "    label_counts = Counter(labels)\n",
    "    entropy = 0\n",
    "    total = len(data)\n",
    "    for count in label_counts.values():\n",
    "        probability = count / total\n",
    "        entropy -= probability * math.log2(probability)\n",
    "    return entropy\n",
    "\n",
    "def information_gain(data, attribute):\n",
    "    \"\"\" Calculate the information gain of an attribute in the dataset \"\"\"\n",
    "    values = set([item[attribute] for item in data])\n",
    "    remainder = 0\n",
    "    total = len(data)\n",
    "    \n",
    "    for value in values:\n",
    "        subset = [item for item in data if item[attribute] == value]\n",
    "        remainder += (len(subset) / total) * entropy(subset)\n",
    "        \n",
    "    return entropy(data) - remainder\n",
    "\n",
    "def id3(data, features, target_attribute):\n",
    "    \"\"\" ID3 algorithm to build a decision tree \"\"\"\n",
    "    labels = [item[target_attribute] for item in data]\n",
    "    if len(set(labels)) == 1:  # If all labels are the same, return a leaf node with that label\n",
    "        return labels[0]\n",
    "    \n",
    "    if len(features) == 0:  # If no more features to split on, return the most common label\n",
    "        return Counter(labels).most_common(1)[0][0]\n",
    "    \n",
    "    # Choose the best attribute to split on\n",
    "    best_attribute = max(features, key=lambda attribute: information_gain(data, attribute))\n",
    "    tree = {best_attribute: {}}\n",
    "    remaining_features = [f for f in features if f != best_attribute]\n",
    "    \n",
    "    # Split the dataset based on the best attribute\n",
    "    for value in set([item[best_attribute] for item in data]):\n",
    "        subset = [item for item in data if item[best_attribute] == value]\n",
    "        subtree = id3(subset, remaining_features, target_attribute)\n",
    "        tree[best_attribute][value] = subtree\n",
    "        \n",
    "    return tree\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example dataset (weather outlook and whether to play golf)\n",
    "    data = [\n",
    "        {'outlook': 'sunny', 'temperature': 'hot', 'humidity': 'high', 'windy': False, 'label': 'no'},\n",
    "        {'outlook': 'sunny', 'temperature': 'hot', 'humidity': 'high', 'windy': True, 'label': 'no'},\n",
    "        {'outlook': 'overcast', 'temperature': 'hot', 'humidity': 'high', 'windy': False, 'label': 'yes'},\n",
    "        {'outlook': 'rainy', 'temperature': 'mild', 'humidity': 'high', 'windy': False, 'label': 'yes'},\n",
    "        {'outlook': 'rainy', 'temperature': 'cool', 'humidity': 'normal', 'windy': False, 'label': 'yes'},\n",
    "        {'outlook': 'rainy', 'temperature': 'cool', 'humidity': 'normal', 'windy': True, 'label': 'no'},\n",
    "        {'outlook': 'overcast', 'temperature': 'cool', 'humidity': 'normal', 'windy': True, 'label': 'yes'},\n",
    "        {'outlook': 'sunny', 'temperature': 'mild', 'humidity': 'high', 'windy': False, 'label': 'no'},\n",
    "        {'outlook': 'sunny', 'temperature': 'cool', 'humidity': 'normal', 'windy': False, 'label': 'yes'},\n",
    "        {'outlook': 'rainy', 'temperature': 'mild', 'humidity': 'normal', 'windy': False, 'label': 'yes'},\n",
    "        {'outlook': 'sunny', 'temperature': 'mild', 'humidity': 'normal', 'windy': True, 'label': 'yes'},\n",
    "        {'outlook': 'overcast', 'temperature': 'mild', 'humidity': 'high', 'windy': True, 'label': 'yes'},\n",
    "        {'outlook': 'overcast', 'temperature': 'hot', 'humidity': 'normal', 'windy': False, 'label': 'yes'},\n",
    "        {'outlook': 'rainy', 'temperature': 'mild', 'humidity': 'high', 'windy': True, 'label': 'no'}\n",
    "    ]\n",
    "\n",
    "    features = ['outlook', 'temperature', 'humidity', 'windy']\n",
    "    target_attribute = 'label'\n",
    "\n",
    "    decision_tree = id3(data, features, target_attribute)\n",
    "    print(\"Decision Tree:\")\n",
    "    print(decision_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebae5440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_tennis=pd.read_csv('E:/2a)Even sem/AIML 6th Sem/1)6th Sem AIML/4)Module 4 AIML/3.csv')\n",
    "#from pandas import DataFrame\n",
    "#df_tennis = DataFrame.from_csv('/home/chaitra/Desktop/ML Lab 2020/fwdmlprograms/3.csv')\n",
    "#df_tennis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a03f0d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def entropy(probs):\n",
    "    return sum([-i * math.log(i, 2) for i in probs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "159e6591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No and yes classes are: play? Counter({'yes': 9, 'no': 5})\n",
      "Entropy of given play tennis dataset: 0.9402859586706309\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def entropy_of_list(a_list):\n",
    "    cnt  = Counter (x for x in a_list)\n",
    "    print('No and yes classes are:', a_list.name, cnt)\n",
    "    num_instances = len(a_list) * 1.0\n",
    "    probs = [x / num_instances for x in cnt.values()]\n",
    "    return entropy(probs)\n",
    "\n",
    "total_entropy = entropy_of_list(df_tennis['play?'])\n",
    "print (\"Entropy of given play tennis dataset:\", total_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a50678ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No and yes classes are: play? Counter({'yes': 9, 'no': 5})\n",
      "Entropy of given play tennis dataset: 0.9402859586706309\n",
      "Information gain calculation of outlook\n",
      "Name: overcast\n",
      "Group:      outlook  temp humidity    wind play?\n",
      "2   overcast   hot     high    weak   yes\n",
      "6   overcast  cool   normal  strong   yes\n",
      "11  overcast  mild     high  strong   yes\n",
      "12  overcast   hot   normal    weak   yes\n",
      "Name: rain\n",
      "Group:    outlook  temp humidity    wind play?\n",
      "3     rain  mild     high    weak   yes\n",
      "4     rain  cool   normal    weak   yes\n",
      "5     rain  cool   normal  strong    no\n",
      "9     rain  mild   normal    weak   yes\n",
      "13    rain  mild     high  strong    no\n",
      "Name: sunny\n",
      "Group:    outlook  temp humidity    wind play?\n",
      "0    sunny   hot     high    weak    no\n",
      "1    sunny   hot     high  strong    no\n",
      "7    sunny  mild     high    weak    no\n",
      "8    sunny  cool   normal    weak   yes\n",
      "10   sunny  mild   normal  strong   yes\n",
      "No and yes classes are: play? Counter({'yes': 4})\n",
      "No and yes classes are: play? Counter({'yes': 3, 'no': 2})\n",
      "No and yes classes are: play? Counter({'no': 3, 'yes': 2})\n",
      "No and yes classes are: play? Counter({'yes': 9, 'no': 5})\n",
      "Information gain for outlook is:0.2467498197744391 \n",
      "\n",
      "Information gain calculation of humidity\n",
      "Name: high\n",
      "Group:      outlook  temp humidity    wind play?\n",
      "0      sunny   hot     high    weak    no\n",
      "1      sunny   hot     high  strong    no\n",
      "2   overcast   hot     high    weak   yes\n",
      "3       rain  mild     high    weak   yes\n",
      "7      sunny  mild     high    weak    no\n",
      "11  overcast  mild     high  strong   yes\n",
      "13      rain  mild     high  strong    no\n",
      "Name: normal\n",
      "Group:      outlook  temp humidity    wind play?\n",
      "4       rain  cool   normal    weak   yes\n",
      "5       rain  cool   normal  strong    no\n",
      "6   overcast  cool   normal  strong   yes\n",
      "8      sunny  cool   normal    weak   yes\n",
      "9       rain  mild   normal    weak   yes\n",
      "10     sunny  mild   normal  strong   yes\n",
      "12  overcast   hot   normal    weak   yes\n",
      "No and yes classes are: play? Counter({'no': 4, 'yes': 3})\n",
      "No and yes classes are: play? Counter({'yes': 6, 'no': 1})\n",
      "No and yes classes are: play? Counter({'yes': 9, 'no': 5})\n",
      "Information gain for humidity is:0.15183550136234136 \n",
      "\n",
      "Information gain calculation of wind\n",
      "Name: strong\n",
      "Group:      outlook  temp humidity    wind play?\n",
      "1      sunny   hot     high  strong    no\n",
      "5       rain  cool   normal  strong    no\n",
      "6   overcast  cool   normal  strong   yes\n",
      "10     sunny  mild   normal  strong   yes\n",
      "11  overcast  mild     high  strong   yes\n",
      "13      rain  mild     high  strong    no\n",
      "Name: weak\n",
      "Group:      outlook  temp humidity  wind play?\n",
      "0      sunny   hot     high  weak    no\n",
      "2   overcast   hot     high  weak   yes\n",
      "3       rain  mild     high  weak   yes\n",
      "4       rain  cool   normal  weak   yes\n",
      "7      sunny  mild     high  weak    no\n",
      "8      sunny  cool   normal  weak   yes\n",
      "9       rain  mild   normal  weak   yes\n",
      "12  overcast   hot   normal  weak   yes\n",
      "No and yes classes are: play? Counter({'no': 3, 'yes': 3})\n",
      "No and yes classes are: play? Counter({'yes': 6, 'no': 2})\n",
      "No and yes classes are: play? Counter({'yes': 9, 'no': 5})\n",
      "Information gain for wind is:0.04812703040826927 \n",
      "\n",
      "Information gain calculation of temp\n",
      "Name: cool\n",
      "Group:     outlook  temp humidity    wind play?\n",
      "4      rain  cool   normal    weak   yes\n",
      "5      rain  cool   normal  strong    no\n",
      "6  overcast  cool   normal  strong   yes\n",
      "8     sunny  cool   normal    weak   yes\n",
      "Name: hot\n",
      "Group:      outlook temp humidity    wind play?\n",
      "0      sunny  hot     high    weak    no\n",
      "1      sunny  hot     high  strong    no\n",
      "2   overcast  hot     high    weak   yes\n",
      "12  overcast  hot   normal    weak   yes\n",
      "Name: mild\n",
      "Group:      outlook  temp humidity    wind play?\n",
      "3       rain  mild     high    weak   yes\n",
      "7      sunny  mild     high    weak    no\n",
      "9       rain  mild   normal    weak   yes\n",
      "10     sunny  mild   normal  strong   yes\n",
      "11  overcast  mild     high  strong   yes\n",
      "13      rain  mild     high  strong    no\n",
      "No and yes classes are: play? Counter({'yes': 3, 'no': 1})\n",
      "No and yes classes are: play? Counter({'no': 2, 'yes': 2})\n",
      "No and yes classes are: play? Counter({'yes': 4, 'no': 2})\n",
      "No and yes classes are: play? Counter({'yes': 9, 'no': 5})\n",
      "Information gain for temperature is:0.029222565658954647 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def information_gain(df, split_attribute_name, target_attribute_name,trace = 0):\n",
    "    print(\"Information gain calculation of\", split_attribute_name)\n",
    "    df_split = df.groupby(split_attribute_name)\n",
    "    for name,group in df_split:\n",
    "        print('Name:',name)\n",
    "        print('Group:',group)\n",
    "        \n",
    "    nobs = len(df.index) * 1.0\n",
    "    df_agg_ent = df_split.agg({target_attribute_name:[entropy_of_list, lambda x:len(x)/ nobs]})[target_attribute_name]\n",
    "    df_agg_ent.columns = ['entropy', 'propobservations']\n",
    "    new_entropy = sum(df_agg_ent['entropy'] * df_agg_ent['propobservations'])\n",
    "    old_entropy = entropy_of_list(df[target_attribute_name])\n",
    "    return old_entropy - new_entropy\n",
    "print (\"Entropy of given play tennis dataset:\",entropy_of_list(dataset['play?']))\n",
    "print('Information gain for outlook is:'+str(information_gain(df_tennis, 'outlook', 'play?')),\"\\n\")\n",
    "print('Information gain for humidity is:'+str(information_gain(df_tennis, 'humidity', 'play?')),\"\\n\")\n",
    "print('Information gain for wind is:'+str(information_gain(df_tennis, 'wind', 'play?')),\"\\n\")\n",
    "print('Information gain for temperature is:'+str(information_gain(df_tennis, 'temp', 'play?')),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292c7281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
